This project aims to build a neural network from the ground up, without relying on any machine learning libraries or frameworks. Working with the classic MNIST dataset, which contains 60,000 training and 10,000 test grayscale images (28Ã—28 pixels) of handwritten digits (0â€“9).


ðŸŽ¯ Objective

Building a model that can accurately classify handwritten digits by implementing all the fundamental components of a neural network manually. This includes:

- Creating custom structures for neurons and layers
- Writing code for forward propagation
- Implementing backpropagation to compute gradients and update weights
- Experimenting with different activation functions and loss functions
- Training using gradient descent and observing how various hyperparameters affect performance
